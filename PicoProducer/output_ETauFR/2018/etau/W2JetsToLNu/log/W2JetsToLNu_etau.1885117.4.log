Could not find platform independent libraries <prefix>
Could not find platform dependent libraries <exec_prefix>
Consider setting $PYTHONHOME to <prefix>[:<exec_prefix>]
ImportError: No module named site
Job start at Sun Feb  7 21:53:04 CET 2021
Running job on machine Linux b7g44n5404.cern.ch 3.10.0-1062.9.1.el7.x86_64 #1 SMP Fri Dec 6 15:49:49 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux, host b7g44n5404.cern.ch
============================================================
$PWD=/pool/condor/dir_12132
$JOBID=1885117
$TASKID=4
$HOSTNAME=b7g44n5404.cern.ch
$TASKCMD=/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/python/processors/picojob.py -y 2018 -d 'mc' -c etau -M ModuleETau --copydir /eos/home-l/lvigilan/output_ETauFR/2018/etau/W2JetsToLNu -t _etau_4 --opt 'jec=False' -i root://cms-xrd-global.cern.ch//store/mc/RunIIAutumn18NanoAODv6/W2JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/NANOAODSIM/Nano25Oct2019_102X_upgrade2018_realistic_v20-v1/40000/8E3D6918-2E8F-6D41-A1B7-DFB20C1ADDAF.root root://cms-xrd-global.cern.ch//store/mc/RunIIAutumn18NanoAODv6/W2JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/NANOAODSIM/Nano25Oct2019_102X_upgrade2018_realistic_v20-v1/40000/A82B5E58-3C98-554E-9F88-ED798C11AB74.root
$WORKDIR=/pool/condor/dir_12132
>>> cd /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src
>>> eval `scramv1 runtime -sh`
>>> cd /pool/condor/dir_12132
$PWD=/pool/condor/dir_12132
>>> /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/python/processors/picojob.py -y 2018 -d 'mc' -c etau -M ModuleETau --copydir /eos/home-l/lvigilan/output_ETauFR/2018/etau/W2JetsToLNu -t _etau_4 --opt 'jec=False' -i root://cms-xrd-global.cern.ch//store/mc/RunIIAutumn18NanoAODv6/W2JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/NANOAODSIM/Nano25Oct2019_102X_upgrade2018_realistic_v20-v1/40000/8E3D6918-2E8F-6D41-A1B7-DFB20C1ADDAF.root root://cms-xrd-global.cern.ch//store/mc/RunIIAutumn18NanoAODv6/W2JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/NANOAODSIM/Nano25Oct2019_102X_upgrade2018_realistic_v20-v1/40000/A82B5E58-3C98-554E-9F88-ED798C11AB74.root
Error in <TGClient::TGClient>: can't open display "localhost:40.0", switching to batch mode...
 In case you run from a remote ssh session, reconnect with ssh -Y
--------------------------------------------------------------------------------
>>> era          = '2018'
>>> year         = 2018
>>> channel      = 'etau'
>>> modname      = 'ModuleETau'
>>> dtype        = 'mc'
>>> kwargs       = {'dtype': 'mc', 'verb': 0, 'era': '2018', 'jec': False, 'year': 2018}
>>> maxevts      = None
>>> outdir       = '.'
>>> copydir      = '/eos/home-l/lvigilan/output_ETauFR/2018/etau/W2JetsToLNu'
>>> infiles      = ['root://cms-xrd-global.cern.ch//store/mc/RunIIAutumn18NanoAODv6/W2JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/NANOAODSIM/Nano25Oct2019_102X_upgrade2018_realistic_v20-v1/40000/8E3D6918-2E8F-6D41-A1B7-DFB20C1ADDAF.root', 'root://cms-xrd-global.cern.ch//store/mc/RunIIAutumn18NanoAODv6/W2JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/NANOAODSIM/Nano25Oct2019_102X_upgrade2018_realistic_v20-v1/40000/A82B5E58-3C98-554E-9F88-ED798C11AB74.root']
>>> outfname     = './pico_etau_etau_4.root'
>>> branchsel    = '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/python/TauFW/PicoProducer/processors/keep_and_drop_skim.txt'
>>> json         = None
>>> prefetch     = False
>>> cwd          = /pool/condor/dir_12132
--------------------------------------------------------------------------------

   ################
   #  ModuleETau  #
   ################

Loading PileupWeightTool for '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/pileup/Data_PileUp_2018_69p2.root' and '/afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/pileup/MC_PileUp_2018_Autumn18.root'
Loading BTagWeightTool for DeepCSV (medium WP)...
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_udsg_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2018_Autumn18_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_c_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2018_Autumn18_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mHistogram 'etau/eff_DeepCSV_b_medium' does not exist in /afs/cern.ch/work/l/lvigilan/TauWork/CMSSW_10_6_17_patch1/src/TauFW/PicoProducer/data/btag/DeepCSV_2018_Autumn18_eff.root! Reverting to default efficiency histogram...[0m
>>> BTagTool: [1m[33mWarning! [0m[33mMade use of default efficiency histograms! The b tag weights from this module should be regarded as placeholders only,
and should NOT be used for analyses. B (mis)tag efficiencies in MC are analysis dependent. Please create your own
efficiency histogram with data/btag/getBTagEfficiencies.py after running all MC samples with BTagWeightTool.[0m
Loading TreeProducerETau for './pico_etau_etau_4.root'
--------------------------------------------------------------------------------
>>> filename     = './pico_etau_etau_4.root'
>>> year         = 2018
>>> dtype        = 'mc'
>>> channel      = 'etau'
>>> ismc         = True
>>> isdata       = False
>>> isembed      = False
>>> tes          = None
>>> tessys       = None
>>> ltf          = 1.0
>>> jtf          = 1.0
>>> dotoppt      = False
>>> dozpt        = False
>>> dojec        = False
>>> dojecsys     = False
>>> dotight      = False
>>> jetCutPt     = 30
>>> bjetCutEta   = 2.7
>>> tauwp        = 0
>>> eleCutPt     = 33
>>> eleCutEta    = 2.1
>>> tauCutPt     = 20
>>> tauCutEta    = 2.3
Pre-select 35426 entries out of 35426 (100.00%)
Processed    10000/   35426 entries, 28.23% (elapsed time    10.1s, curr speed    0.990 kHz, avg speed    0.990 kHz), accepted      109/   10001 events ( 1.09%)
Processed    20000/   35426 entries, 56.46% (elapsed time    15.3s, curr speed    1.912 kHz, avg speed    1.304 kHz), accepted      217/   20001 events ( 1.08%)
Processed    30000/   35426 entries, 84.68% (elapsed time    21.4s, curr speed    1.644 kHz, avg speed    1.401 kHz), accepted      314/   30001 events ( 1.05%)
Processed 35426 preselected entries from root://cms-xrd-global.cern.ch//store/mc/RunIIAutumn18NanoAODv6/W2JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/NANOAODSIM/Nano25Oct2019_102X_upgrade2018_realistic_v20-v1/40000/8E3D6918-2E8F-6D41-A1B7-DFB20C1ADDAF.root (35426 entries). Finally selected 371 entries
Pre-select 25809 entries out of 25809 (100.00%)
Processed    10000/   25809 entries, 38.75% (elapsed time     8.6s, curr speed    1.158 kHz, avg speed    1.158 kHz), accepted      102/   10001 events ( 1.02%)
Processed    20000/   25809 entries, 77.49% (elapsed time    13.6s, curr speed    2.012 kHz, avg speed    1.470 kHz), accepted      207/   20001 events ( 1.03%)
Processed 25809 preselected entries from root://cms-xrd-global.cern.ch//store/mc/RunIIAutumn18NanoAODv6/W2JetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/NANOAODSIM/Nano25Oct2019_102X_upgrade2018_realistic_v20-v1/40000/A82B5E58-3C98-554E-9F88-ED798C11AB74.root (25809 entries). Finally selected 276 entries
Total time 42.4 sec. to process 61235 events. Rate = 1443.8 Hz.
>>> cwd          = /pool/condor/dir_12132
>>> ls           = ['x509_voms', '.update.ad', 'tmp', 'condor_exec.exe', '.chirp.config', '_condor_stdout', '.machine.ad', 'pico_etau_etau_4.root', '.job.ad', 'var', 'lvigilan.cc']
>>> getstorage('/eos/home-l/lvigilan/output_ETauFR/2018/etau/W2JetsToLNu'), <EOS("/eos/home-l/lvigilan/output_ETauFR/2018/etau/W2JetsToLNu") at 0x2ac849368450>
>>> Executing: 'cp ./pico_etau_etau_4.root /eos/home-l/lvigilan/output_ETauFR/2018/etau/W2JetsToLNu'
>>> Removing './pico_etau_etau_4.root'...
>>> picojob.py done after 305.9 seconds

Job complete at Sun Feb  7 21:58:31 CET 2021
Took 5 minutes 27 seconds040 (1885117.004.000) 02/07 21:58:31 Finished transferring output files
...
005 (1885117.004.000) 02/07 21:58:31 Job terminated.
	(1) Normal termination (return value 0)
		Usr 0 00:00:30, Sys 0 00:00:02  -  Run Remote Usage
		Usr 0 00:00:00, Sys 0 00:00:00  -  Run Local Usage
		Usr 0 00:00:30, Sys 0 00:00:02  -  Total Remote Usage
		Usr 0 00:00:00, Sys 0 00:00:00  -  Total Local Usage
	12774  -  Run Bytes Sent By Job
	9877  -  Run Bytes Received By Job
	12774  -  Total Bytes Sent By Job
	9877  -  Total Bytes Received By Job
	Partitionable Resources :    Usage  Request Allocated 
	   Cpus                 :     0.97        1         1 
	   Disk (KB)            :    81           1    195329 
	   Memory (MB)          :   187        2000      2000 
...
